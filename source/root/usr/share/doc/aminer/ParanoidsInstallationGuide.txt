Preamble:
=========

This document provides an installation guide to all those paranoid
users, who

* do not trust their systems to be in a completely sane state
  when starting the analysis,
* do not trust the aminer analysis features without understanding
  (and perhaps auditing) them and
* do not trust the aminer autoconfiguration features to perform
  correctly or want to avoid them accepting parts of the insane
  system state as normal.

Thus the following instructions will show how to enable each small
feature manually to create full blown and really paranoid realtime
mining configuration for syslog data.


Creating the basic service configuration:
=========================================

AMiner supports splitting the configuration loaded by the parent
and child process. As the parent usually has to be run with root
privileges, one might want to avoid loading the full configuration
here.

Steps:

* Create parent configuration:

cd /etc/aminer

If permission denied user has to be added to user group aminer. A reboot
might be required.

Create a new config file

touch config.py

Define a dictionary for the configuration properties by adding 

config_properties = {}

to config.py.

Define the list of log resources to read from: the resources named here
do not need to exist when aminer is started. This will just result in
a warning. However if they exist, they have to be readable by the aminer
process! Supported types are:
 * file://[path]: Read data from file, reopen it after rollover
 * unix://[path]: Open the path as UNIX local socket for reading

config_properties['LogResourceList'] = []

Define the uid/gid of the process that runs the calculation after opening
the log files:

config_properties['AMinerUser'] = 'aminer'
config_properties['AMinerGroup'] = 'aminer'

Optional: Define the path, where aminer will listen for incoming remote
          control connections. When missing, no remote control socket
		  will be created.
		  
		  config_properties['RemoteControlSocket'] = '/var/run/aminer-remote.socket'
		  
		  Enable the remote control socket: it will allow to adjust
		  aminer child settings on the fly without reloading of the configuration
		  or editing of persistency files. In default configuration,
		  only root user can connect to the socket. The remote control
		  commands are executed within the analysis child process usually
		  running  as a dedicated less-privileged user.

Define the child configuration file:

config_properties['AnalysisConfigFile'] = 'analysis.py'

Read the analyis from this file. That part of configuration is separated
from the main configuration so that it can be loaded only within the
analysis child. Non-absolute path names are interpreted relatively to
the main configuration file (config.py). When empty, this configuration
has to contain the configuration for the child also.

While not fully configured, you may want to start with an empty input
file. A paranoid aminer instance will report everything not explicitely
whitelisted as an error. Basically you would get your whole syslog echoed
back, just with an amplification factor applied. In that case change
the property "LogResourceList" to:

config_properties['LogResourceList'] = ['file:///etc/aminer/test.log']

and do:

touch /etc/aminer/test.log
chmod 0600 /etc/aminer/test.log
 
* Create child configuration:

touch analysis.py

Add again "config_properties = {}".

The AMiner reads and stores information to be used between multiple invocations
in a persistency directory. The directory must only be accessible to
the 'AMinerUser' but not group/world readable. On violation, AMiner will
refuse to start. When undefined, '/var/lib/aminer' is used. Therefore
optionally add

config_properties['Core.PersistenceDir'] = <path>

Optional: You may want to define the "MailAlerting.TargetAddress" parameter
          to receive e-mail alerts and data reports. Therefore add
		  
		  config_properties['MailAlerting.TargetAddress'] = 'root@localhost'
		  
		  When undefined, no e-mail notification hooks are added. Sender
		  address of e-mail alerts. When undefined, "sendmail" implementation
		  on host will decide, which sender address should be used.
		  
		  config_properties['MailAlerting.FromAddress'] = 'root@localhost'
		  
		  Define, which text should be prepended to the standard aminer
		  subject. Defaults to "AMiner Alerts:"
		  
		  config_properties['MailAlerting.SubjectPrefix'] = 'AMiner Alerts:'
		  
		  Define a grace time after startup before aminer will react to
		  an event and send the first alert e-mail. Defaults to 0 (any
		  event can immediately trigger alerting).
		  
		  config_properties['MailAlerting.AlertGraceTime'] = 0
		  
		  Define how many seconds to wait after a first event triggered
		  the alerting procedure before really sending out the e-mail.
		  In that timespan, events are collected and will be sent all 
		  using a single e-mail. Defaults to 10 seconds.
		  
		  config_properties['MailAlerting.EventCollectTime'] = 10
		  
		  Define the minimum time between two alert e-mails in seconds
		  to avoid spamming. All events during this timespan are collected
		  and sent out with the next report. Defaults to 600 seconds.
		  config_properties['MailAlerting.MinAlertGap'] = 600
		  
		  Define the maximum time between two alert e-mails in seconds.
		  When undefined this defaults to "MailAlerting.MinAlertGap".
		  Otherwise this will activate an exponential backoff to reduce
		  messages during permanent error states by increasing the alert
		  gap by 50% when more alert-worthy events were recorded while
		  the previous gap time was not yet elapsed.
		  
		  config_properties['MailAlerting.MaxAlertGap'] = 600
		  
		  Define how many events should be included in one alert mail
		  at most. This defaults to 1000
		  
		  config_properties['MailAlerting.MaxEventsPerMessage'] = 1000

Now define the analysis pipeline: Define the function build_analysis_pipeline(analysis_context)
to create pipeline for parsing the log data and applien other features.
It has also to define an AtomizerFactory to instruct AMiner how to process
incoming data streams to create log atoms from them.

First import the FirstMatchModelElement and the SequenceModelElement, 
and define an empty list of services and an empty parsering:

from aminer.parsing import FirstMatchModelElement
from aminer.parsing import SequenceModelElement

parsing_model = SequenceModelElement('model', [])

Create all global handler lists and append the real handlers later on.
Use this filter to distribute all atoms to the analysis handlers.

from aminer.analysis import AtomFilters

atom_filter = AtomFilters.SubhandlerFilter(None)
anomaly_event_handlers = []

Now define the AtomizerFactory using the model. A simple line based one
is usually sufficient.

from aminer.input import SimpleByteStreamLineAtomizerFactory

analysis_context.atomizer_factory = SimpleByteStreamLineAtomizerFactory(
      parsing_model, [atom_filter], anomaly_event_handlers,
      default_timestamp_paths=['/model/syslog/time'])

Report all unparsed atoms to the event handlers and add a new match patch
detector (further information see "Adding detection for new parser pathes" 
in the remaining file):

from aminer.input import SimpleUnparsedAtomHandler

atom_filter.add_handler(
      SimpleUnparsedAtomHandler(anomaly_event_handlers),
      stop_when_handled_flag=True)

from aminer.analysis import NewMatchPathDetector

new_match_path_detector = NewMatchPathDetector(
      analysis_context.aminer_config, anomaly_event_handlers, auto_include_flag=True)
analysis_context.register_component(new_match_path_detector, component_name=None)
atom_filter.add_handler(new_match_path_detector)

Optional: Include the e-mail notification handler only if the configuration
          parameter was set.
		  
		  from aminer.events import DefaultMailNotificationEventHandler
		  
		  if DefaultMailNotificationEventHandler.CONFIG_KEY_MAIL_TARGET_ADDRESS in analysis_context.aminer_config.config_properties:
            mail_notification_handler = DefaultMailNotificationEventHandler(
              analysis_context.aminer_config)
		    analysis_context.register_component(
              mail_notification_handler, component_name=None)
            anomaly_event_handlers.append(mail_notification_handler)

		  
During testing the "StreamPrinterEventHandler" is useful to get the aminer
events printed to stdout. Therefore add:

from aminer.events import StreamPrinterEventHandler
anomaly_event_handlers.append(StreamPrinterEventHandler(analysis_context.aminer_config))

* Allow python code imports:

AMiner does not use the default dist/site-packages to load code. See Design.txt
"Loading of python code" for explanation. By default pytz is used for
timestamp handling, so add it:

ln -s /usr/lib/python3/dist-packages/pytz /etc/aminer/conf-enabled


* Check for configuration errors:

AMiner --Foreground --Config /etc/aminer/config.py

Here you will get some warnings. The rationale behind that is
not to be silent about code that is not hardened to the maximum
level. The code should be secure in the current execution environment
where

* semantics of kernel syscall interface did not change over time
* component is used as recommended in documentation
* core system services or users are not already under control
  of an adversery

Here are short explanations for the warnings:

* WARNING: SECURITY: No secure open yet due to missing openat in python!

  Python2.7 os module does not support "openat". Without that,
  Linux kernel does not provide any secury way to open a file
  in an untrusted directory, e.g. "/var/log", a directory owned
  by user "syslog". The only way using "(f)chdir/open" repeats
  is not really practical. But usually when your syslog user is
  controlled by an adversery, you will be done anyway. 

* WARNING: SECURITY: Open should use O_PATH, but not yet available in python

  Linux allos to open files and directories with "O_PATH" flag.
  The file descriptor can be used as a reference to the file but
  not for reading/writing. Thus leak of file descriptor to other
  process (no close before exit) or standard stdin/stdout write
  data corruption can be avoided. Aminer (or your specific setup)
  would need to have such a vulnerability in first place to let
  the "O_PATH" hardening become effective.

* WARNING: SECURITY: No checking for backdoor access via POSIX ACLs, use "getfacl" from "acl" package to check manually.

  Apart from the standard file mode flags, each file or directory
  may also have "POSIX ACLs" attached. When not checking for them,
  an adversery may use them to gain access even to newly created
  files which is not expected when just looking at the file mode.
  But again, this would require, that someone has acquired access
  to some core system file directories, e.g. "/var/log", beforehand.

* WARNING: SECURITY: unsafe unlink (unavailable unlinkat/linkat should be used, but not available in python)

  Same as "No secure open yet due to missing openat" from above.


When up and running using a test file, you can test the aminer
output adding a test line:

head -n 1 /var/log/syslog >> /etc/aminer/test.log

As there is no hardcoded parsing model or parsing model generator
configured, you should get:

Unparsed data (1 lines)
  Jun 19 00:10:01 somehost.local rsyslogd: [origin ...


Adding the first parsing model element:
=======================================

When using the first line from your syslog for testing, it should
be a line from the syslog daemon startup. Hence the default parsing
model might match the syslog daemon output on your system. To
enable add

ln -s /etc/aminer/conf-available/generic/SyslogPreambleModel.py /etc/aminer/conf-enabled

and edit your configuration:

import SyslogPreambleModel
syslog_preamble_model = SyslogPreambleModel.get_model()

from aminer.parsing import AnyByteDataModelElement

parsing_model = SequenceModelElement('model', [
      syslog_preamble_model,
      AnyByteDataModelElement('logmessage')]) # to parse the remaining log line

Furthermore change the default_timestamp_paths of the AtomizerFactory to
['/model/syslog/time'].

When starting aminer again, no warning about unparsed data should
be printed. If still present, the model might not match your line.


* Creating or modifying a model:

Unlike logfile parsing tools, e.g. logcheck and many SIEMs, AMiner
does not use regular expressions, that have to be applied to each
log line separately. The parsing model is more like a tree, having
a common trunk, e.g., the syslog preamble with timestamp and hostname,
and specific service outputs being handled in model branches.
See Readme.txt "Concepts" for more information.

Create a model file e.g. in "conf-available/local" and link it
or directly create it in "conf-enabled", whatever suits your production
process best.

mkdir /etc/aminer/conf-available/local
cp /etc/aminer/conf-available/generic/RsyslogParsingModel.py /etc/aminer/conf-available/local

Edit /etc/aminer/conf-available/local/RsyslogParsingModel.py

See ParsingModel.txt for documentation on the available model
elements. Especially the "DebugModelElement" can be inserted at
any position in your model to see where parsing breaks when parsing
failures seem unexplainable.

When even parsing of the syslog preamble using SyslogPreambleModel
fails, this can be adjusted to your needs also. You may have to
supply a different time model element, or host name model in:

/etc/aminer/conf-available/SyslogPreambleModel.py

or even switch to MultiLocaleDateTimeModelElement. See source
code documentation in those files, e.g.
/usr/lib/logdata-anomaly-miner/aminer/parsing/DateTimeModelElement.py
/usr/lib/logdata-anomaly-miner/aminer/parsing/MultiLocaleDateTimeModelElement.py

and Python format string specification in

https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior

* Debugging a model:

Being paranoid and using only own, handcrafted models, one will
usually experience problems that some atom is not handled as expected.
To follow the parsing model, a DebugMatchContext can be used instead
of the default context. It is slower but it will capture state
information about the matching process. With remote control (see
below), debugging can even occur while AMiner is processing data.
Remote control code for that purpose could be:

  from aminer.parsing import DebugMatchContext
  match_context = DebugMatchContext('Your test input here')
  # Working with registered components is handy...
  match = analysis_context.registered_components_by_name['ParsingModel'].get_match_element('', match_context)
  remote_control_response = 'Result: %s, debug info %s' % (str(match), match_context.get_debug_info())

Without remote control change in 

/usr/lib/logdata-anomaly-miner/aminer/input/ByteStreamLineAtomizer.py 

the match_context and add an appropriate output, e.g.,

  match_context = DebugMatchContext(line_data)
  match_element = self.parsing_model.get_match_element('', match_context)
  print('Result: %s, debug info %s' % (str(match_element), match_context.get_debug_info()))

Also the import of DebugMatchContext might be required.

* Contributing to the model templates:

If your model configuration might be useful for others and you
are willing and legally alowed to publish it under "GNU GPL v3",
please consider sending the change to a maintainer or filing a
bug, both available at https://launchpad.net/logdata-anomaly-miner


Adding detection for new parser pathes:
=======================================

Usually, your system will not emit an arbitrary large number of
differently structured loglines. In normal operation with a given
set of configuration options and standard software use patterns,
each service only produces a small subset of log message types
compared to all the messages it could theoretically create. On
the other hand, service failures or attacks often result in new
message types. Hence, each new parser path corresponding
to a new message type should cause some distrust.

You may use the configuration defined before, but when really paranoid,
following changes might be useful:

* Disable autoinclusion: auto_include_flag = False
* Register as named component: component_name = 'DefaultNewMatchPathDetector'

  from aminer.analysis import NewMatchPathDetector
  new_match_path_detector = NewMatchPathDetector(
      analysis_context.aminer_config, anomaly_event_handlers, auto_include_flag=False)
  analysis_context.register_component(
      new_match_path_detector, component_name='DefaultNewMatchPathDetector')
  atom_filter.add_handler(new_match_path_detector)

With automatic inclusion enabled, the detector would complain
about each new path seen exactly once and then add it to the list
of accepted pathes. Setting this flag to True during configuration
phase is very good to shorten the configuration time, but it will
also work without that. And therefore the "component_name" comes
in handy.

As you may have run aminer with autoinclusion enabled already
during "Adding the first parsing model element", you may want
to delete all the included patterns by stopping aminer and deleting
"/var/lib/aminer/NewMatchPathDetector/Default".


* Using different detectors for subset of sources:

When running aminer on a remote logging host, you may process
messages from completely different systems. While e.g. a sudo
message is completely normal on one machine, it might be completely
unexpected on another one. To use different detectors for different
host groups, a filter has to be installed to separate the data:

  * Create different NewMatchPathDetector instances with unique
    persistance IDs:

  new_match_path_detector_a = NewMatchPathDetector(
      analysis_context.aminer_config, anomaly_event_handlers,
      peristence_id='WwwHostsGroup', auto_include_flag=False)

  * Create the filter:

  from aminer.analysis import AtomFilters
  hostname_value_filter = AtomFilters.MatchValueFilter(
      '/model/syslog/host',
      {'host-a': new_match_path_detector_a, ...},
      default_new_match_path_detector)
  atom_filter.add_handler(hostname_value_filter)

In production, you may want to create all those groups in a loop,
reading from a list of host/group mappings.


Using the remote control interface for runtime changes:
=======================================================

When really running with auto_include_flag=False, each unknown path
would be reported over and over again. On some installations you
may want to roll out the known path persistency files containing
simple JSON data and load them when starting aminer. Therefore
adding the new item to the persistency file is sufficient. This
has to be done while aminer is NOT running, otherwise shutdown
may overwrite the files.

More common is to add the changes via the remote control interface
e.g.

  * manually (for demonstration as shown below)
  * using custom integration code, e.g. embedded in your SIEM
    that is receiving the aminer events
  * use orchestration tools


* Verify remote control is working:

For manual inclusion, remote control socket has to be enabled
and accessible. To have more robust configuration procedures,
the detectors should be registered as named components. To verify,
that remote control is working, just execute:

AMinerRemoteControl --ControlSocket /var/run/aminer-remote.socket --Exec 'remote_control_response = analysis_context.get_registered_component_names()'
Remote execution response: [u'DefaultNewMatchPathDetector']

The command executed is executed inside the running aminer child
process. See man page of AMinerRemoteControl for more information.
For multiline Pyhton code, writing it to a file and using "--ExecFile"
for invocation is recommended.


* Modify the detector state:

AMinerRemoteControl --ControlSocket /var/run/aminer-remote.socket --Data '["/model/services/rsyslog/msg/statechange/type/HUPed"]' --Exec 'for path_name in remote_control_data: analysis_context.get_component_by_name("DefaultNewMatchPathDetector").known_path_set.add(path_name)' --Exec 'analysis_context.get_component_by_name("DefaultNewMatchPathDetector").do_persist()'


Detect missing logs:
====================

Logdata analysis might detect anomalies within the data as long
as data is available. On small scale setups, that might not be
such an issue, but in larger setups, nobody might notice, that
one service or even host stopped to emit log messages. The reason
for that might be an error or an attack, that is left to the admin
to find out.

Here is an example how to detect that hosts stop sending logs
and to generate alerts:

  from aminer.analysis import MissingMatchPathValueDetector
  missing_match_path_value_detector = MissingMatchPathValueDetector(
      analysis_context.aminer_config, '/model/syslog/host',
      anomaly_event_handlers, auto_include_flag=True, default_interval=24*3600)
  analysis_context.register_component(
      missing_match_path_value_detector,
      component_name='DefaultMissingMatchPathValueDetector')
  atom_filter.add_handler(missing_match_path_value_detector)

The default interval should fit your operational procedures:

* When aminer is used to detect malfunction of business critical
  processes not monitored via other means, the interval should
  be so low to react early enough to fullfil your SLAs. A busy
  webserver not serving (and logging) a page for 2 minutes might
  be of relevance. You may want to feed those alerts into your
  monitoring solution to have event-deduplication e.g. during
  maintenance downtimes.

* For problems you would not start dealing with immediately, where
  the service is not that important, a longer timeout might be
  suitable. Just let aminer wait some before alerting to see if
  the problem vanishes without interaction.

By setting the "component_name" in the code example above, you
again make it easier to perform remote control actions on the
running miner, e.g.

* Change check interval for single value:

AMinerRemoteControl --ControlSocket /var/run/aminer-remote.socket --Exec 'analysis_context.get_component_by_name("DefaultMissingMatchPathValueDetector").set_check_value("buildhost.localdomain", 12*3600)'

* Remove value from monitoring:

AMinerRemoteControl --ControlSocket /var/run/aminer-remote.socket --Exec 'analysis_context.get_component_by_name("DefaultMissingMatchPathValueDetector").remove_check_value("buildhost.localdomain")'

* Force persistency write when your changes were that important:

AMinerRemoteControl --ControlSocket /var/run/aminer-remote.socket --Exec 'analysis_context.get_component_by_name("DefaultMissingMatchPathValueDetector").do_persist()'


Apply whitelisting to parsed entries:
=====================================

Even when a log-atom was parsed using parsing model parts already
matching previous atoms, this does not mean, that this should
be treated a normal situation. As opposed to SIEM solutions, that
frequently apply blacklisting for event generation, the aminer
rules engine can be used to whitelist elements based on combinations
of parameters. For performance reasons, those rules can also be
arranged in a tree-like fashion. Rules can also be used to invoke
actions when it matches. Parsed data that does not match any rule
will trigger an event.

See "/usr/share/doc/aminer/demo/ubuntu-syslog-config.py" for example
how the WhitelistViolationDetector is added to the configuration.
