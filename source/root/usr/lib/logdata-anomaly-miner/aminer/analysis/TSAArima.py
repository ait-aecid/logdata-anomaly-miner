"""This module is a detector for testing purposes of the ETD"""

# ToDo:
# x) Udpate-Function
# x) no generation of the time window

import time

from aminer import AMinerConfig
from aminer.AnalysisChild import AnalysisContext
from aminer.events import EventSourceInterface
from aminer.input import AtomHandlerInterface
from aminer.util import TimeTriggeredComponentInterface
from aminer.util import PersistencyUtil
import statsmodels.api as sm_api
import numpy as np
from scipy.signal import find_peaks, savgol_filter

import pandas as pd
import datetime
import pytz
import pmdarima as pm

class TSAArima(AtomHandlerInterface, TimeTriggeredComponentInterface, EventSourceInterface):
    """This class is used for testing purposes"""

    def __init__(self, aminer_config, anomaly_event_handlers, event_type_detector, persistence_id='Default'):

        # event_type_detector. Used to get the eventNumbers and values of the variables, etc.
        self.event_type_detector = event_type_detector
        # Add the varTypeDetector to the list of the modules, which use the event_type_detector.
        self.event_type_detector.add_following_modules(self)
        # Significance level of the estimatedd values
        self.alpha = 0.05
        # List of the time steps
        self.time_step_list = []
        # Number of division of the time window to the time step
        self.num_division_time_step = 10
        # History of the time windows
        self.time_window_history = []

        self.df = [] # pd.read_csv(path, header=0)
        self.syscall_types = [] # self.df.columns[2:]
        return

    def receive_atom(self, log_atom):
        print(self.event_type_detector.total_records)
        return True

    def get_time_trigger_class(self):
        """Get the trigger class this component can be registered for. This detector only needs persisteny triggers in real time."""
        return AnalysisContext.TIME_TRIGGER_CLASS_REALTIME

    def do_timer(self, trigger_time):
        """Checks if current ruleset should be persisted"""
        return 600

    def do_persist(self):
        """Immediately write persistence data to storage."""  # No support for empirical distributions !!!
        return

    def allowlist_event(self, event_type, sorted_log_lines, event_data, allowlisting_data):
        """
        Allowlist an event generated by this source using the information emitted when generating the event.
        @return a message with information about allowlisting
        @throws Exception when allowlisting of this special event using given allowlisting_data was not possible.
        """
        if event_type != 'Analysis.%s' % self.__class__.__name__:
            raise Exception('Event not from this source')
        raise Exception('No allowlisting for algorithm malfunction or configuration errors')

    def calculate_time_steps(self, counts):
        """Returns a list of the timestep lenghts in seconds, if no timestep should be created the value is set to -1"""
        # List of the resulting time_steps
        time_step_list = []
        # Initialize time_window_history
        self.time_window_history = [[] for _ in range(len(counts))]
        # Minimal size of the time step
        min_lag = max(int(0.2*self.event_type_detector.num_sections_waiting_time_for_TSA),1)
        for data in counts:
            # Apply the autocorrelation function to the data of the single event types.
            corr = list(map(abs, sm_api.tsa.acf(data, nlags=len(data), fft=True)[min_lag:]))
            corr = np.array(corr)
            print('corr: %s'%corr)
            # Apply the Savitzky-Golay-Filter to the list corr, to smooth the curve and get better results
            corrfit = savgol_filter(corr, min(max(3,int(len(corr)/10)-int(int(len(corr)/10) % 2 == 0)), 101), 1)
            print('corrfit: %s'%corrfit)
            
            # Find the highest peak and set the time-step as the index + lag
            highest_peak_index = np.argmax(corrfit)
            time_step_list.append((highest_peak_index + min_lag) / self.num_division_time_step)

        return time_step_list

    def passed_timewindow(self, event_number, count):
        """This function makes a TSA of the given counts and raises an alert if the counts do not match the expected appearances of the eventtype"""

        # Add the new count to the history and shorten it, if neccessary
        self.time_window_history[even_number].append(count)
        if len(self.time_window_history[even_number]) > 2 * self.num_division_time_step:
            self.time_window_history[even_number] = self.time_window_history[even_number][-self.num_division_time_step:]

        rows_list = []
        slided_df = mailCupCom.slide_event(syscall_type, ts, tw)
        anomalous_points = mailCupCom.slide_attack_intervals(ts, tw, slided_df,0)
        anomalous_points = sorted(anomalous_points)
        anomalous_indices = []
        anomaly_start = anomalous_points[0]
        history_list = slided_df[slided_df['ts'] <= anomaly_start - 50*ts][syscall_type].values.tolist()
        slided_ts_list = slided_df[slided_df['ts'] > anomaly_start - 50*ts]['ts'].values.tolist()
        slided_test_data = slided_df[slided_df['ts'] > anomaly_start - 50*ts][syscall_type].values.tolist()
        for point in anomalous_points:
            index = (point - slided_ts_list[0] )/ts
            anomalous_indices.append(int(index))

        for index in range(len(slided_test_data)):
            error = "None"
            try:
                lower, pred, upper = Syscall.one_step_prediction(history_list[-history:], alpha)
            except ValueError:
                error = "ValueError"
                lower, pred, upper = 0,0,0
            except np.linalg.LinAlgError:
                error = "LinAlgError"
                lower, pred, upper = 0,0,0
            anomaly = False
            if index in anomalous_indices:
                anomaly = True
            true_value = slided_test_data[index]
            history_list.append(true_value)
            tmp_dict = {"index": index, "timestamp": slided_ts_list[index], "error": error,
                        "true_value": true_value, "prediction": pred,
                        "lower_bound": lower, "upper_bound": upper, "tw": tw, "ts": ts,
                        "history": history, "alpha": alpha, "anomaly": anomaly}
            rows_list.append(tmp_dict)

        evaluation = pd.DataFrame(rows_list)
        name = r"mailCupCom"
        name = name + str(syscall_type) + "-" + str(history) + "-" + str(tw) + "-" + str(ts) +\
                "-" + str(alpha) + ".csv"
        evaluation.to_csv(name, index=False, header=True)
        print('EventNumber: %s, Count: %s'%(event_number, count))
        return


    def slide_event(self, syscall_type, ts, tw):
        # assume ts,tw in seconds
        min_index = self.df['ts'].iloc[0]
        max_index = self.df['ts'].iloc[-1]
        indices = []
        i=0
        while min_index + i*ts <= max_index - tw:
            indices.append(min_index + i*ts)
            i += 1
        agg_data = np.zeros(len(indices))
        for j in range(len(indices)):
            agg_data[j] = sum(self.df[(indices[j] <= self.df['ts']) & (self.df['ts'] < indices[j] + tw)][syscall_type])
        d = {'ts': indices, syscall_type: agg_data}
        df_slided = pd.DataFrame(d)
        return df_slided

    def slide_attack_intervals(self, ts, tw, slided_df, interval_expansion = 0):
        anomalous_points = []
        for attack_interval in self.attack_intervals:
            l = attack_interval[0] - tw - interval_expansion
            ll = min(slided_df[slided_df['ts'] >= l]['ts'])
            r = attack_interval[1] + interval_expansion
            rr = max(slided_df[slided_df['ts'] <= r]['ts'])
            i = 0
            anomalous_points.extend(slided_df[(slided_df['ts'] <= rr) & (slided_df['ts'] >= ll)]['ts'])
        anomalous_points = set(anomalous_points)
        anomalous_points = list(anomalous_points)
        return anomalous_points

    def set_attack_intervals(self, path):
        line_above_success = False
        start_time = None
        end_time = None
        attacks = []
        with open(path) as file:
            for line in file:
                if not ("success" in line):
                    line_above_success = False
                    line_split = line.split()
                    time = line_split[3]
                    time_split = time.split(':')
                    hour = int(time_split[0])
                    minute = int(time_split[1])
                    second = int(time_split[2])
                    start_time = datetime.datetime(year=2020, month=3, day=int(line_split[2]), hour=hour, minute=minute, second=second, tzinfo=pytz.utc)
                    start_time_ts = int(start_time.timestamp())
                elif not (line_above_success):
                    line_above_success = True
                    line_split = line.split()
                    time = line_split[3]
                    time_split = time.split(':')
                    hour = int(time_split[0])
                    minute = int(time_split[1])
                    second = int(time_split[2])
                    end_time = datetime.datetime(year=2020, month=3, day=int(line_split[2]), hour=hour, minute=minute, second=second, tzinfo=pytz.utc)
                    end_time_ts = int(end_time.timestamp())
                    attacks.append([start_time_ts,end_time_ts])
        self.attack_intervals = attacks


def one_step_prediction(history, alpha):
    model = pm.auto_arima(history,
                            seasonal=False, error_action='ignore',
                            suppress_warnings=True)
    fitted_model = model.fit(history)
    prediction = fitted_model.predict(n_periods=1, return_conf_int=True,
                                        alpha=alpha)
    pred = prediction[0][0]
    upper = prediction[1][0][1]
    lower = prediction[1][0][0]
    return lower, pred, upper


